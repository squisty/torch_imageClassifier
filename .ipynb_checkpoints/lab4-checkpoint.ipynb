{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYUHk6sxO2pO"
   },
   "source": [
    "<img src=\"img/dsci572_header.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Advanced Deep Learning: Transfer Learning and GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, there are two mini-projects: one about transfer learning and the other about Generative Adversarial Networks (GAN).\n",
    "\n",
    "You are required to complete **only one** of these mini-projects for this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "<hr>\n",
    "\n",
    "rubric={mechanics:3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4aecf0223bc592cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/)\n",
    "- Upload a PDF version of your lab notebook to Gradescope, in addition to the .ipynb file. Use the Webpdf option of Jupyter Lab if PDF doesn't work.\n",
    "- Add a link to your GitHub repository here: https://github.ubc.ca/mds-2021-22/DSCI_572_lab4_squist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from PIL import Image\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'font.size': 14, 'axes.labelweight': 'bold', 'axes.grid': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Kaggle\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91yxVPKkO2qa"
   },
   "source": [
    "We are going to run this notebook on the cloud using [Kaggle](https://www.kaggle.com). Kaggle offers 30 hours of free GPU usage per week which should be much more than enough for this lab. To get started, follow these steps:\n",
    "\n",
    "1. Go to https://www.kaggle.com/kernels\n",
    "2. Make an account if you don't have one, and verify your phone number (to get access to GPUs)\n",
    "3. Select `+ New Notebook`\n",
    "4. Go to `File -> Import Notebook`\n",
    "5. Upload this notebook\n",
    "6. On the right-hand side of your Kaggle notebook, make sure:\n",
    "  - `Internet` is enabled.\n",
    "  - In the `Accelerator` dropdown, choose `GPU` when you're ready to use it (you can turn it on/off as you need it).\n",
    "    \n",
    "Once you've done all your work on Kaggle, you can download the notebook from Kaggle. That way any work you did on Kaggle won't be lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Project 1: Transfer Learning\n",
    "<hr>\n",
    "\n",
    "rubric={accuracy:15}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you're going to practice transfer learning. We're going to develop a model that can detect the following 6 cat breeds in this Kaggle [dataset](https://www.kaggle.com/solothok/cat-breed):\n",
    "\n",
    "1. American Short hair\n",
    "2. Bengal\n",
    "3. Maine Soon\n",
    "4. Ragdoll\n",
    "5. Scottish Fold\n",
    "6. Sphinx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this dataset \n",
    "1. Click `+ Add data` at the top right of the notebook.\n",
    "2. Search for **\"cat-breed\"** and click `Add`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: CNN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you should build a CNN model to classify images of cats based on their breeds.\n",
    "\n",
    "In Kaggle, running the follow cell should print out `\"Using device: cuda\"` which means a GPU is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make use of the GPU, you should:\n",
    "1. Move your model to the GPU after creating it using this syntax:\n",
    "\n",
    "```python\n",
    "model.to(device)\n",
    "```\n",
    "\n",
    "2. In your training/validation loops, each batch should be moved to the GPU using syntax like:\n",
    "\n",
    "```python\n",
    "for X, y in dataloader:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some guidelines for building your binary classification CNN from scratch:\n",
    "\n",
    "- You may use any architecture you like.\n",
    "- This is the path to the data in your notebook: `../input/cat-breed/cat-breed/`\n",
    "- You should use an `IMAGE_SIZE = 200` pixels in your data loader (the raw images could be any size).\n",
    "- **You must train your model for at least 20 epochs and print or plot the accuracy for each epoch on the validation data for us to see.**\n",
    "\n",
    ">If you want to take a look at the images after making a `train_loader`, try this code:\n",
    "\n",
    "```python\n",
    "# Plot samples\n",
    "sample_batch = next(iter(train_loader))\n",
    "plt.figure(figsize=(10, 8)); plt.axis(\"off\"); plt.title(\"Sample Training Images\")\n",
    "plt.imshow(np.transpose(utils.make_grid(sample_batch[0], padding=1, normalize=True),(1, 2, 0)));\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Feature Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you should leverage a pre-trained model customized with your own layer(s) on top, to build a CNN classifier that can identify various cat breeds.\n",
    "\n",
    "- You can use any model you wish. I used `densenet`.\n",
    "- Train your model for at least 20 epochs.\n",
    "- Comment on the performance of this model compared to your \"from scratch\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer goes here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final exercise, you should fine-tune your model by updating all or some of the layers during training.\n",
    "\n",
    "- You can fine-tune as many layers as you like: the whole model, or particular layers. Experiment with both modes of fine-tuning, and find which works better.\n",
    "- Train your model for at least 20 epochs.\n",
    "- Comment on the performance of this model compared to your \"from scratch\" and \"feature extractor\" models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer goes here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Project 2: Generative Adversarial Networks\n",
    "<hr>\n",
    "\n",
    "rubric={accuracy:15}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you're going to practice building a generative adversarial network (GAN).\n",
    "\n",
    "GANs are incredibly hard to train especially with small datasets, so you may not get good results in this exercise. But don't worry about that, it is just important to get some practice and experience with these types of NNs.\n",
    "\n",
    "> For this exercise, you're not limited to a particular dataset, you can use any dataset you like. The `cat-breed` or any other suitable one on Kaggle is acceptable, as long as you can show the progress of your trained GAN on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Kaggle, running the follow cell should print out `\"Using device: cuda\"` which means a GPU is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make use of the GPU, you should:\n",
    "- Move your model to the GPU after creating it with the syntax:\n",
    "\n",
    "```python\n",
    "model.to(device)\n",
    "```\n",
    "\n",
    "- In your training loop, each batch should be moved to the GPU using syntax like:\n",
    "\n",
    "```python\n",
    "for X, _ in dataloader:\n",
    "    X = X.to(device)\n",
    "    ...\n",
    "```\n",
    "\n",
    "- Note above that we don't need the labels for training a GAN, so I ignore it by un-packing it into an underscore `_` (which is typically Python convention for variables we don't need)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, prepare the data by creating a `data_loader`. This is the path to the data in your notebook if you choose to use the `cat-breed` dataset: `../input/cat-breed/cat-breed/`.\n",
    "\n",
    ">If you want to take a look at the images after making a `data_loader`, try this code:\n",
    "\n",
    "```python\n",
    "# Plot samples\n",
    "sample_batch = next(iter(data_loader))\n",
    "plt.figure(figsize=(10, 8)); plt.axis(\"off\"); plt.title(\"Sample Training Images\")\n",
    "plt.imshow(np.transpose(utils.make_grid(sample_batch[0], padding=1, normalize=True),(1, 2, 0)));\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Create the Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to create a generator for our GAN. You can reuse/modify the code from Lecture 8, or build your own. Use a `LATENT_SIZE=100` for the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Create the Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to create a discriminator for our GAN. You can reuse/modify the code from Lecture 8, or build your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4: Initialize Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs can be quite sensitive to the initial weights assigned to each layer when we instantiate the model. Instantiate your generator and discriminator and then specify their initial weights as follows:\n",
    "- `Conv2d()` layers: normal distribution with `mean=0.0` and `std=0.02`\n",
    "- `ConvTranspose2d()` layers: normal distribution with `mean=0.0` and `std=0.02`\n",
    "- `BatchNorm2d()` layers: normal distribution with `mean=1.0` and `std=0.02` for the weights, zeroes for the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5: Train your GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have all the ingredients you need now to train a GAN, so give it a go!\n",
    "\n",
    "You should track the loss of your model as epochs progress and show at least one example of an image output by your trained generator (better yet, record the evolution over time of how your generator is doing, like we did in Lecture 8). **Your results may not be great and that's perfectly okay, you should just show _something_**.\n",
    "\n",
    "Here are some tips:\n",
    "- You will likely need to train for at least `NUM_EPOCHS=100` (and maybe more).\n",
    "- I find that the hardest part about training GANs is that the discriminator \"overpowers\" the generator, making it hard for the generator to learn how to create realistic images. There are lots of things you can do to try and balance your generator and discriminator, such as: play with the optimizer's hyperparameters, change the architectures of your models, etc.\n",
    "- Here's a good set of [tips and tricks for training GANs](https://github.com/soumith/ganhacks).\n",
    "- Once again, GANs are notoriously difficult to train (even more so with smaller data sets like we have here). Don't worry if you're not getting amazing results. This is all about practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lab4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:dsci572env]",
   "language": "python",
   "name": "conda-env-dsci572env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
